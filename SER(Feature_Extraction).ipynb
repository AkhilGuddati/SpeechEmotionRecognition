{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "f1k1SedFih7Z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import librosa\n",
        "np.set_printoptions(suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "5eFoXaTQuDo3"
      },
      "outputs": [],
      "source": [
        "audiopaths = pd.read_csv('./datapath0.csv')\n",
        "audiopaths = np.array(audiopaths)\n",
        "m,n = audiopaths.shape\n",
        "\n",
        "def noise(audio):\n",
        "  noise = np.random.normal(0, audio.std(), audio.size)\n",
        "  aug_audio = audio + (noise*0.1)\n",
        "  return aug_audio\n",
        "\n",
        "def stretch(audio):\n",
        "  sth_audio = librosa.effects.time_stretch(audio, rate=0.5)\n",
        "  return sth_audio\n",
        "\n",
        "def scale_pitch(audio,sr):\n",
        "  return librosa.effects.pitch_shift(audio, sr, 0.7)\n",
        "\n",
        "def ex_features(audio):\n",
        "  data_row = np.array([])\n",
        "\n",
        "  mel_audio = np.mean(librosa.feature.melspectrogram(audio).T, axis=0)  # mel-spectrogram\n",
        "  data_row = np.hstack((data_row, mel_audio))\n",
        "  \n",
        "  zcr_audio = np.mean(librosa.feature.zero_crossing_rate(audio).T, axis=0)    # zero-crossing-rate\n",
        "  data_row = np.hstack((data_row, zcr_audio))\n",
        "\n",
        "  rms_audio = np.mean(librosa.feature.rms(audio).T, axis=0)   # RMS energy\n",
        "  data_row = np.hstack((data_row, rms_audio))\n",
        "\n",
        "  chroma_audio = np.mean(librosa.feature.chroma_stft(audio).T, axis=0) # chromagram\n",
        "  data_row = np.hstack((data_row, chroma_audio))\n",
        "  \n",
        "  mfcc_audio = np.mean(librosa.feature.mfcc(audio).T, axis=0)   # mel frequency cepstral coefficients\n",
        "  data_row = np.hstack((data_row, mfcc_audio))\n",
        "\n",
        "  return data_row\n",
        "\n",
        "def get_features(audio_wav):\n",
        "  audio,sr = librosa.load(audio_wav, res_type='kaiser_fast', duration=2.5, sr=44100, offset=0.6)\n",
        "\n",
        "  or_audio = ex_features(audio)    # row 0\n",
        "  data_block = np.array(or_audio)\n",
        "\n",
        "  noisy_audio = ex_features(noise(audio))   # row 1\n",
        "  data_block = np.vstack((data_block, noisy_audio))\n",
        "\n",
        "  st_audio = stretch(audio)\n",
        "  pitch_audio = scale_pitch(st_audio, sr)\n",
        "  al_audio = ex_features(pitch_audio)   # row 2\n",
        "  data_block = np.vstack((data_block, al_audio))\n",
        "\n",
        "  return data_block\n",
        "\n",
        "def make_array(i):\n",
        "  ar=[]\n",
        "  audio_wav = audiopaths[i][0]\n",
        "  data_block = get_features(audio_wav)\n",
        "  label = (audiopaths[i][1])\n",
        "  ar.append([label,data_block[0]])\n",
        "  ar.append([label,data_block[1]])\n",
        "  ar.append([label,data_block[2]])\n",
        "  return ar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "QtHRMtoi3WRM"
      },
      "outputs": [],
      "source": [
        "#part 1\n",
        "data_set = []\n",
        "\n",
        "for i in range(0,3000):\n",
        "  data_set.extend(make_array(i))\n",
        "dataframe = pd.DataFrame(data_set)\n",
        "\n",
        "dataframe.to_csv('./augmented_dataset1.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6W49byMO3WJP"
      },
      "outputs": [],
      "source": [
        "#part 2\n",
        "data_set = []\n",
        "\n",
        "for i in range(3000,6000):\n",
        "  data_set.extend(make_array(i))\n",
        "dataframe = pd.DataFrame(data_set)\n",
        "\n",
        "dataframe.to_csv('./augmented_dataset2.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lT_LkG0K3WAN"
      },
      "outputs": [],
      "source": [
        "#part 3\n",
        "data_set = []\n",
        "\n",
        "for i in range(6000,9000):\n",
        "  data_set.extend(make_array(i))\n",
        "dataframe = pd.DataFrame(data_set)\n",
        "\n",
        "dataframe.to_csv('./augmented_dataset3.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWq0piK73mlN"
      },
      "outputs": [],
      "source": [
        "#part 4\n",
        "data_set = []\n",
        "\n",
        "for i in range(9000,m):\n",
        "  data_set.extend(make_array(i))\n",
        "dataframe = pd.DataFrame(data_set)\n",
        "\n",
        "dataframe.to_csv('./augmented_dataset4.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuH0nnIx4e95"
      },
      "outputs": [],
      "source": [
        "augmented_dataset0=pd.concat(\n",
        "    map(pd.read_csv, ['./augmented_dataset1.csv', './augmented_dataset2.csv', './augmented_dataset3.csv','./augmented_dataset4.csv']), ignore_index=True)\n",
        "augmented_dataset0.to_csv(\"./augmented_dataset0.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "F3C4ZHYBC6fK"
      },
      "outputs": [],
      "source": [
        "# Fixing exported csv\n",
        "dataframe = pd.read_csv(\"./augmented_dataset0.csv\")\n",
        "dataframe[\"1\"] = dataframe['1'].replace(\"           \",',',regex=True)\n",
        "dataframe[\"1\"] = dataframe['1'].replace(\"          \",',',regex=True)\n",
        "dataframe[\"1\"] = dataframe['1'].replace(\"         \",',',regex=True)\n",
        "dataframe[\"1\"] = dataframe['1'].replace(\"        \",',',regex=True)\n",
        "dataframe[\"1\"] = dataframe['1'].replace(\"       \",',',regex=True)\n",
        "dataframe[\"1\"] = dataframe['1'].replace(\"      \",',',regex=True)\n",
        "dataframe[\"1\"] = dataframe['1'].replace(\"     \",',',regex=True)\n",
        "dataframe[\"1\"] = dataframe['1'].replace(\"    \",',',regex=True)\n",
        "dataframe[\"1\"] = dataframe['1'].replace(\"   \",',',regex=True)\n",
        "dataframe[\"1\"] = dataframe['1'].replace(\"  \",',',regex=True)\n",
        "dataframe[\"1\"] = dataframe['1'].replace(\" \",',',regex=True)\n",
        "dataframe[\"1\"] = dataframe['1'].replace(\",,\",',',regex=True)\n",
        "dataframe[\"1\"] = dataframe['1'].replace(\"\\n\",'',regex=True)\n",
        "dataframe[\"1\"] = dataframe['1'].replace(\"\\[,\",'[',regex=True)\n",
        "dataframe[\"1\"] = dataframe['1'].replace(\",\\]\",']',regex=True)\n",
        "dataframe.to_csv(\"./Final_Data.csv\",index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SER(Feature Extraction).ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
